data:
  train:
    lmdb_path: datasets/lmdb/refcoco/train.lmdb
    mode: train
    image_size:
      - 224
      - 224

  val:
    lmdb_path: datasets/lmdb/refcoco/val.lmdb
    mode: val
    image_size:
      - 224
      - 224

  test:
    lmdb_path: datasets/lmdb/refcoco/testA.lmdb
    mode: test
    image_size:
      - 224
      - 224

  val_plus:
    lmdb_path: datasets/lmdb/refcoco+/val.lmdb
    mode: val
    image_size:
      - 224
      - 224

  train_plus:
    lmdb_path: datasets/lmdb/refcoco+/train.lmdb
    mode: train
    image_size:
      - 224
      - 224

  test:
    lmdb_path: datasets/lmdb/refcoco+/testA.lmdb
    mode: test
    image_size:
      - 224
      - 224

train_settings:
  batch_size: 45
  scaler_step: 8
  start_epoch: 0
  epochs: 300
  lr_decay: 0.5
  milestones: [60, 150, 250]
  clip_grad: 2
  checkpoint_step: 5

optimizer_params:
  lr: 5.0e-4
  weight_decay: 0.001


model:
  # text_backbone: "sentence-transformers/multi-qa-distilbert-cos-v1"
  # visual_backbone: facebook/maskformer-swin-large-coco

  ImageEncoder:
    image_size:
      - 224
      - 224
    embedding_dim: 300
    embedding_dim_internal: 170
    conv_kernel_size: 6
    conv_num_layers: 2

  SiamEncoder:
    embedding_dim: 300
    mlp_ratio: 4
    num_heads: 5
    num_blocks: 10
    projection_dropout: 0.25
    attention_dropout: 0.25
    feed_forward_dropout: 0.25

  TextConvEncoder:
    seq_len: 100
    embedding_dim: 300
    embedding_dim_internal: 300
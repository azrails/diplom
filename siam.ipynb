{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = './runs'\n",
    "import math\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from utils import config\n",
    "from data_utils import dataset\n",
    "from model import vit\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from model.loss import ContrastiveLoss, ContrastiveSoftMax\n",
    "\n",
    "#sets random\n",
    "random_seed=42\n",
    "random.seed(42)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\" )\n",
    "\n",
    "match device:\n",
    "    case \"cuda\":\n",
    "        torch.cuda.manual_seed_all(random_seed)\n",
    "    case \"mps\":\n",
    "        torch.mps.manual_seed(random_seed)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GloVe\n",
    "glove_file = 'glove.6B.300d.txt'\n",
    "word2vec_temp_file = get_tmpfile(\"glove_word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_temp_file)\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_temp_file)\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, embeding_model):\n",
    "        self.embeddings = embeding_model\n",
    "    \n",
    "    def tokenize(self, sent_tokens):\n",
    "        tokens_embeddings = []\n",
    "        for t in sent_tokens:\n",
    "            if t in self.embeddings:\n",
    "                tokens_embeddings.append(self.embeddings[t])\n",
    "            else:\n",
    "                tokens_embeddings.append(np.zeros(300))\n",
    "        return torch.FloatTensor(tokens_embeddings)\n",
    "\n",
    "tokenizer = Tokenizer(glove_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4513500, 642600, 13087201)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = config.load_config(\"configs/stage_one.yaml\")\n",
    "image_embeder = vit.ImgEncoder(**conf['model']['ImageEncoder'])\n",
    "text_embeder = vit.TextConvEncoder(**conf['model']['TextConvEncoder'])\n",
    "siam_model = vit.SiamEncoder(**conf['model']['SiamEncoder'])\n",
    "(sum(p.numel() for p in image_embeder.parameters() if p.requires_grad), \n",
    "sum(p.numel() for p in text_embeder.parameters() if p.requires_grad), \n",
    "sum(p.numel() for p in siam_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "siam_model_params = torch.nn.ModuleList([image_embeder, text_embeder, siam_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(siam_model_params.parameters(),  **conf['optimizer_params'])\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer,\n",
    "            milestones=conf['train_settings']['milestones'],\n",
    "            gamma=conf['train_settings']['lr_decay']\n",
    "        )\n",
    "losses = []\n",
    "val_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = conf['model']['TextEncoder']['seq_len']\n",
    "\n",
    "def tokenize_sent_batch(sents_batch):\n",
    "    tokenized_sentences = []\n",
    "    length_list = []\n",
    "    for sent in sents_batch:\n",
    "        sent_tokens = sent.strip().split()\n",
    "        if len(sent_tokens) > SEQ_LEN:\n",
    "            sent_tokens = sent_tokens[:SEQ_LEN]\n",
    "        tokenized_sentences.append(tokenizer.tokenize(sent_tokens))\n",
    "        length_list.append(len(sent_tokens))\n",
    "    #pad sequences to Text Embeder len\n",
    "    tokenized_sentences[0] = torch.concat((tokenized_sentences[0], torch.zeros(SEQ_LEN - length_list[0], 300)), dim=0)\n",
    "    seqs = pad_sequence(tokenized_sentences, batch_first=True)\n",
    "    return seqs, torch.tensor(length_list, dtype=torch.uint8)\n",
    "\n",
    "\n",
    "def pading_sentences_fn(data):\n",
    "    masks_tensors, sents, labels = zip(*data)\n",
    "    masks_tensors = torch.stack(masks_tensors)\n",
    "    sents, lens = tokenize_sent_batch(sents)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    return masks_tensors, sents, lens, labels\n",
    "\n",
    "\n",
    "train_dataset = dataset.ReferenceDataset(\n",
    "    **conf['data']['train'],\n",
    ")\n",
    "train_data_coco_plus = dataset.ReferenceDataset(\n",
    "    **conf['data']['train_plus'],\n",
    ")\n",
    "# union_train_dataset = ConcatDataset([train_dataset, train_data_coco_plus])\n",
    "union_train_dataset = ConcatDataset([train_dataset, ])\n",
    "train_data = DataLoader(\n",
    "    union_train_dataset,\n",
    "    batch_size=conf['train_settings']['batch_size'],\n",
    "    shuffle=True,\n",
    "    # pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=6,\n",
    "    collate_fn=pading_sentences_fn\n",
    ")\n",
    "\n",
    "val_dataset = dataset.ReferenceDataset(\n",
    "    **conf['data']['val'],\n",
    ")\n",
    "val_dataset_plus = dataset.ReferenceDataset(\n",
    "    **conf['data']['val_plus'],\n",
    ")\n",
    "# union_val_dataset = ConcatDataset([val_dataset, val_dataset_plus])\n",
    "union_val_dataset = ConcatDataset([val_dataset, ])\n",
    "val_data = DataLoader(\n",
    "    union_val_dataset,\n",
    "    batch_size=conf['train_settings']['batch_size'],\n",
    "    shuffle=False,\n",
    "    # pin_memory=True,\n",
    "    drop_last=True,\n",
    "    num_workers=6,\n",
    "    collate_fn=pading_sentences_fn\n",
    ")\n",
    "epoch = (conf['train_settings']['start_epoch'], conf['train_settings']['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_checkpoint(path_to_checkpoints_folder, checkpoint_name, conf, text_embedder, img_embedder, siam_model, optimizer, scheduler, train_losses, val_scores):\n",
    "    \"\"\"\n",
    "    Save model, config, score\n",
    "    \"\"\"\n",
    "    path_to_checkpoint = os.path.join(path_to_checkpoints_folder, checkpoint_name)\n",
    "    os.makedirs(path_to_checkpoint, exist_ok=True)\n",
    "    config.dump_config(path_to_checkpoint, conf, 'config.yaml')\n",
    "\n",
    "    path_to_metrics = os.path.join(path_to_checkpoint, 'metrics.json')\n",
    "    with open(path_to_metrics, 'w') as f:\n",
    "        json.dump({'train_losses': train_losses, 'val_scores': val_scores}, f, indent=4)\n",
    "    \n",
    "    path_to_model = os.path.join(path_to_checkpoint, 'model.pt')\n",
    "    torch.save(\n",
    "                {\n",
    "                    'text_embedder_state_dict': text_embedder.state_dict(),\n",
    "                    'img_embedder_state_dict': img_embedder.state_dict(),\n",
    "                    'siam_model_state_dict': siam_model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict()\n",
    "                \n",
    "                },\n",
    "                path_to_model\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f91d7d8d1e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "# # backward hook with module name\n",
    "# def get_backward_hook(module_name: str):\n",
    "    \n",
    "#     class BackwardHook:\n",
    "#         name: str\n",
    "            \n",
    "#         def __init__(self, name):\n",
    "#             self.name = name\n",
    "            \n",
    "#         def __call__(self, module_name, grad_input, grad_output):\n",
    "#             for i, g_in in enumerate(grad_input):\n",
    "#                 if torch.any(torch.isnan(g_in)):\n",
    "#                     print(f\"{module_name}'s {i}th input gradient is nan\")\n",
    "#                     raise Exception\n",
    "#                 if torch.any(torch.isinf(g_in)):\n",
    "#                     print(f\"{module_name}'s {i}th output gradient is inf\")\n",
    "#                     raise Exception\n",
    "#             for i, g_out in enumerate(grad_output):\n",
    "#                 if torch.any(torch.isnan(g_out)):\n",
    "#                     print(f\"{module_name}'s {i}th output gradient is nan\")\n",
    "#                     raise Exception\n",
    "#                 if torch.any(torch.isinf(g_out)):\n",
    "#                     print(f\"{module_name}'s {i}th output gradient is inf\")\n",
    "#                     raise Exception\n",
    "\n",
    "#     return BackwardHook(module_name)\n",
    "\n",
    "# for name, module in text_embeder.named_modules():\n",
    "#     module.register_full_backward_hook(get_backward_hook(name))\n",
    "\n",
    "# for name, module in image_embeder.named_modules():\n",
    "#     module.register_full_backward_hook(get_backward_hook(name))\n",
    "\n",
    "# for name, module in siam_model.named_modules():\n",
    "#     module.register_full_backward_hook(get_backward_hook(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, text_embedder, img_embedder, siam_model, optimizer, checkpoint_path, scheduler, conf, device=\"cpu\", tb_path=None):\n",
    "        self.text_embedder = text_embedder.to(device)\n",
    "        self.img_embedder = img_embedder.to(device)\n",
    "        self.siam_model = siam_model.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.tb_path = tb_path\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.loss_fn = ContrastiveLoss(margin=2.0)\n",
    "        self.conf = conf\n",
    "        if self.tb_path is not None:\n",
    "            self.writer =  SummaryWriter(self.checkpoint_path, self.tb_path)\n",
    "\n",
    "    def train(self, train_data, val_data, epochs, losses, val_scores, checkpoint_step=1, scheduler_step=1):\n",
    "        if self.tb_path is not None:\n",
    "          for i, ls in enumerate(losses):\n",
    "            self.writer.add_scalar(\"Loss_epoche/train\", ls, i)\n",
    "          for i, vl in enumerate(val_scores):\n",
    "            self.writer.add_scalar(\"MSE/val\", vl, i)\n",
    "        for epoch in tqdm(range(epochs[0], epochs[1]), desc='Epochs'):\n",
    "            train_loss = self.train_epoch(train_data, epoch)\n",
    "            val_acc, cosine_acc, negative_mse = self.validate(val_data)\n",
    "            if self.tb_path is not None:\n",
    "                self.writer.add_scalar(\"Cosine/val\", cosine_acc , epoch )\n",
    "                self.writer.add_scalar(\"Contrastive_epoche/train\", train_loss, epoch)\n",
    "                self.writer.add_scalar(\"MSE/val\", val_acc, epoch)\n",
    "                self.writer.add_scalar(\"NEGATIVE_MSE/val\", negative_mse, epoch)\n",
    "            print(f\"Epoch: {epoch}/{epochs} - Loss: {train_loss:.4f}\")\n",
    "            losses.append(train_loss)\n",
    "            val_scores.append(val_acc)\n",
    "            if epoch % scheduler_step == 0:\n",
    "                self.scheduler.step()\n",
    "            if epoch % checkpoint_step == 0:\n",
    "                self.conf['train_settings']['start_epoch'] = epoch + 1\n",
    "                save_checkpoint(\n",
    "                    self.checkpoint_path,\n",
    "                    f'epoch_{epoch}',\n",
    "                    self.conf,\n",
    "                    self.text_embedder,\n",
    "                    self.img_embedder,\n",
    "                    self.siam_model,\n",
    "                    self.optimizer,\n",
    "                    self.scheduler,\n",
    "                    losses,\n",
    "                    val_scores\n",
    "                    )\n",
    "\n",
    "    def train_epoch(self, train_data, epoch):\n",
    "        self.img_embedder.train()\n",
    "        self.text_embedder.train()\n",
    "        self.siam_model.train()\n",
    "        img_embedder = torch.compile(self.img_embedder, mode='max-autotune', fullgraph=True)\n",
    "        text_embedder = torch.compile(self.text_embedder, mode='max-autotune', fullgraph=True)\n",
    "        siam_model = torch.compile(self.siam_model, mode='max-autotune', fullgraph=True)\n",
    "        # img_embedder = self.img_embedder\n",
    "        # text_embedder = self.text_embedder\n",
    "        # siam_model = self.siam_model\n",
    "        loss = []\n",
    "        for step, (masks_tensor, sents, _, labels) in enumerate(tqdm(train_data, desc=\"Training\", leave=False)):\n",
    "            #calc step\n",
    "            self.optimizer.zero_grad()\n",
    "            with torch.autocast(device_type=self.device):\n",
    "                masks_tensor = masks_tensor.to(self.device)\n",
    "                sents = sents.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                img_embeddings = img_embedder(masks_tensor)\n",
    "                text_embeddings = text_embedder(sents)\n",
    "                img_encoded, _ = siam_model(img_embeddings)\n",
    "                text_encoded, _ = siam_model(text_embeddings)\n",
    "                contrastive_loss = self.loss_fn(img_encoded, text_encoded, labels)\n",
    "            step_loss = contrastive_loss\n",
    "            step_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            contrastive_loss = contrastive_loss.cpu().detach().item()\n",
    "            loss.append(contrastive_loss)\n",
    "            if self.tb_path is not None:\n",
    "                self.writer.add_scalar(\"Contrastive_loss/train\", contrastive_loss, epoch * len(train_data) + step)\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def non_equal_distanse(self, labels, inverse=False):\n",
    "        negative_labels = labels.clone()\n",
    "        if inverse:\n",
    "            negative_labels[labels==0]=-1\n",
    "            negative_labels[labels==1]= 1    \n",
    "        else:\n",
    "            negative_labels[labels==0]=1\n",
    "            negative_labels[labels==1]=0\n",
    "        return negative_labels\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self, val_data):\n",
    "        self.img_embedder.eval()\n",
    "        self.text_embedder.eval()\n",
    "        self.siam_model.eval()\n",
    "        mse_acc = []\n",
    "        negative_mse = []\n",
    "        coss_acc = []\n",
    "        mse = torch.nn.functional.mse_loss\n",
    "        cos_los = torch.nn.functional.cosine_embedding_loss\n",
    "        for _, (masks_tensor, sents, _, labels) in enumerate(tqdm(val_data, desc=\"Validating\", leave=False)):\n",
    "            with torch.autocast(device_type=self.device):\n",
    "                masks_tensor = masks_tensor.to(self.device)\n",
    "                sents = sents.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                img_embeddings = self.img_embedder(masks_tensor)\n",
    "                text_embeddings = self.text_embedder(sents)\n",
    "                img_encoded, _ = self.siam_model(img_embeddings)\n",
    "                text_encoded, _ = self.siam_model(text_embeddings)\n",
    "                mse_loss = mse(img_encoded*labels[:,None,None], text_encoded*labels[:, None, None])\n",
    "                negative_labels = self.non_equal_distanse(labels)\n",
    "                negative_mse_loss = mse(img_encoded*negative_labels[:,None,None], text_encoded*negative_labels[:, None, None])\n",
    "                cos_neg_labels = self.non_equal_distanse(labels, inverse=True)\n",
    "                cs = cos_los(img_encoded, text_encoded, cos_neg_labels)\n",
    "            coss_acc.append(cs.cpu().detach().item())\n",
    "            mse_acc.append(mse_loss.cpu().detach().item())\n",
    "            negative_mse.append(negative_mse_loss.cpu().detach().item())\n",
    "        return np.mean(mse_acc), np.mean(coss_acc), np.mean(negative_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c4fb462c76408b832ca3748695c5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c4e1f85700482095d236366c6dab6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0521 16:23:45.054000 140270230462464 torch/_inductor/utils.py:945] [0/0] not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d678636f3741d399c0be6fbdec17d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/(0, 300) - Loss: 1.1363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9306b78508654d9c836811574eea60d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef60a3e86aed4ca39e6853d082c5fa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/(0, 300) - Loss: 1.0098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758f648aa4ca4f6faee888cc68f3cc7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93453786393a494fb48259a2d01fbc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/(0, 300) - Loss: 1.0100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f446a559374f06a2563e87b16e9a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b504578c9314c44b3543e20caf7af23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/(0, 300) - Loss: 1.0103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7f60f910d74c95ae2a641a2dfdda95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0d3578039444c686a8f74b0d3159d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/(0, 300) - Loss: 1.0154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb308b259db4a5a8fa5b576891d1dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'PowBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(text_embeder, image_embeder, siam_model, optimizer, BASE_DIR, scheduler, conf, device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_scores\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_data, val_data, epochs, losses, val_scores, checkpoint_step, scheduler_step)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE/val\u001b[39m\u001b[38;5;124m\"\u001b[39m, vl, i)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs[\u001b[38;5;241m0\u001b[39m], epochs[\u001b[38;5;241m1\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     val_acc, cosine_acc, negative_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(val_data)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[10], line 74\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, train_data, epoch)\u001b[0m\n\u001b[1;32m     72\u001b[0m     contrastive_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(img_encoded, text_encoded, labels)\n\u001b[1;32m     73\u001b[0m step_loss \u001b[38;5;241m=\u001b[39m contrastive_loss\n\u001b[0;32m---> 74\u001b[0m \u001b[43mstep_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m contrastive_loss \u001b[38;5;241m=\u001b[39m contrastive_loss\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/diplom/diplom/env/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diplom/diplom/env/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diplom/diplom/env/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function 'PowBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(text_embeder, image_embeder, siam_model, optimizer, BASE_DIR, scheduler, conf, device, 'tb')\n",
    "trainer.train(train_data, val_data, epoch, losses, val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
